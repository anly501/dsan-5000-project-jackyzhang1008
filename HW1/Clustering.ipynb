{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Clustering\"\n",
        "bibliography: references.bib\n",
        "---"
      ],
      "id": "92ebb0af"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Introduction**\n",
        "\n",
        "For this project we are going to use clustering on DOSE EQUIVALENT RATE (nSv/h) and try to find out that if we are able to find out if we are able to find out and group different range of rate.\n",
        "\n",
        "# **Theory**\n",
        "\n",
        "## **K-Means Clustering**\n",
        "\n",
        "K-Menas clustering start by randomly k point and then interactively moves them to shorten the distance until getting closer to the point. Morover, when choosing the model, the Elbow Methold is used to determined the suitable number of clusters. The Silhouette Method assesses how similar an object is to its own cluster compared to others.\n",
        "\n",
        "## **DBSCAN**\n",
        "\n",
        "This types of cluster point out what point are closer tougher, and make outlier lie alone in low density area. DBSCAN would form clusters in dense areas and identify isolated trees in sparse areas as outliers. Moreover, DBSCAN uses epsilon to find the neighborhood.\n",
        "\n",
        "## **Hierarchical Clustering**\n",
        "\n",
        "This model builds a hierarchical of cluster by using divisive or agglomerate approach. Like building a decision tree with the point on the leave. Dendrograms are used to visualize the formation of clusters in hierarchical clustering.\n",
        "\n",
        "# **Methods**\n",
        "\n",
        "## **Data selection**\n"
      ],
      "id": "b6e1a5bd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.cluster import KMeans, Birch, AgglomerativeClustering, DBSCAN\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "001663c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = pd.read_csv('../data/Cleaned/merged_data.csv')\n",
        "data = data.sample(n=10000)\n",
        "# take only the columns that are needed for clustering\n",
        "data_cluster = data[['DOSE EQUIVALENT RATE (nSv/h)']]"
      ],
      "id": "7b2e66eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **K-Means**\n",
        "\n",
        "### Elbow\n"
      ],
      "id": "9326e0e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "wcss = []  # Within-cluster sum of squares\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "    kmeans.fit(data_cluster)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "# Plotting the results of the Elbow method\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, 11), wcss, marker='o')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "e544eb21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Silhousette Score\n"
      ],
      "id": "ccf30be5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = data[[\"DOSE EQUIVALENT RATE (nSv/h)\"]]\n",
        "\n",
        "# Finding the optimal number of clusters using silhouette scores\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)  # Testing for number of clusters from 2 to 10\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    cluster_labels = kmeans.fit_predict(X)\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Plotting the silhouette scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, silhouette_scores, marker='o')\n",
        "plt.title(\"Silhouette Scores for Different Numbers of Clusters\")\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"Silhouette Score\")\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "28a71487",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data[['DOSE EQUIVALENT RATE (nSv/h)']])\n",
        "\n",
        "# Performing k-means clustering with 3 clusters\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)\n",
        "clusters = kmeans.fit_predict(data_scaled)\n",
        "\n",
        "# Adding the cluster information to the original dataframe\n",
        "data['Cluster'] = clusters\n",
        "\n",
        "# Display the first few rows with cluster labels\n",
        "clustered_data_head = data.head()\n",
        "\n",
        "# Summary of clusters\n",
        "cluster_summary = data['Cluster'].value_counts()\n",
        "\n",
        "clustered_data_head, cluster_summary"
      ],
      "id": "2c5020f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **DBSCAN Clustering**\n"
      ],
      "id": "9cdd7d3c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "eps_values = np.arange(0.1, 2.0, 0.1)\n",
        "min_samples = 5  # Default value for min_samples\n",
        "\n",
        "# Extracting the 'DOSE EQUIVALENT RATE (nSv/h)' column for clustering\n",
        "dose_data = data['DOSE EQUIVALENT RATE (nSv/h)'].values.reshape(-1, 1)\n",
        "\n",
        "# Dictionary to store the number of clusters for each eps value\n",
        "num_clusters = {}\n",
        "\n",
        "# Perform DBSCAN clustering for each eps value and store the number of clusters\n",
        "for eps in eps_values:\n",
        "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(dose_data)\n",
        "    labels = db.labels_\n",
        "    \n",
        "    # Number of clusters in labels, ignoring noise if present\n",
        "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    num_clusters[eps] = n_clusters\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(list(num_clusters.keys()), list(num_clusters.values()), marker='o')\n",
        "plt.title('DBSCAN Clustering: Number of Clusters for Different eps Values')\n",
        "plt.xlabel('eps Value')\n",
        "plt.ylabel('Number of Clusters')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "e1d99c80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "eps_selected = 1.0\n",
        "db_selected = DBSCAN(eps=eps_selected, min_samples=min_samples).fit(dose_data)\n",
        "labels_selected = db_selected.labels_\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present\n",
        "n_clusters_selected = len(set(labels_selected)) - (1 if -1 in labels_selected else 0)\n",
        "\n",
        "# Adding the cluster labels to the original dataset\n",
        "data['Cluster'] = labels_selected\n",
        "\n",
        "# Displaying the number of clusters and the first few rows of the dataset with cluster labels\n",
        "n_clusters_selected, data.head()"
      ],
      "id": "110d7b24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hierarchical Clustering\n"
      ],
      "id": "82f1541c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dose_data = data[['DOSE EQUIVALENT RATE (nSv/h)']].values\n",
        "\n",
        "# Using agglomerative hierarchical clustering\n",
        "linked = linkage(dose_data, method='ward')\n",
        "\n",
        "# Plotting the dendrogram\n",
        "plt.figure(figsize=(10, 7))\n",
        "dendrogram(linked, labels=data['LOCATION_NAME'].values, orientation='top')\n",
        "plt.title('Hierarchical Clustering Dendrogram (Agglomerative)')\n",
        "plt.xlabel('Location')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()"
      ],
      "id": "24e59cf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Results**\n",
        "\n",
        "Hierarchical clustering proved to be illustrative for understanding data relationships, while K-means offered simplicity and ease of implementation. DBSCAN's capacity to handle noise and identify outliers was uniquely beneficial.\n",
        "\n",
        "# **Conclusions**\n",
        "\n",
        "Our exploration of clustering method shows key insights into the inherent structures within our dataset. Hierarchical clustering proved to be illustrative for understanding data relationships, while K-means offered simplicity and ease of implementation. DBSCAN's capacity to handle noise and identify outliers was uniquely beneficial.\n",
        "\n",
        "# **References**\n",
        "\n",
        "[@usepa2021]"
      ],
      "id": "176b1789"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}