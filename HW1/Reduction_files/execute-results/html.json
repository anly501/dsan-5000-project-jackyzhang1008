{
  "hash": "5fbcdc8b5b4bb48ff0739f193927c313",
  "result": {
    "markdown": "---\ntitle: \"Reduction\"\nbibliography: references.bib\n---\n\n# Dimensionality Reduction with PCA\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport torch \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndata = pd.read_csv('../data/Cleaned/merged_data.csv')\n\n# One-hot encoding the 'LOCATION_NAME' column\nencoder = OneHotEncoder(sparse=False)\nlocation_encoded = encoder.fit_transform(data[['LOCATION_NAME']])\n\n# Create a DataFrame from the encoded columns\nlocation_encoded_df = pd.DataFrame(location_encoded, columns=encoder.get_feature_names_out(['LOCATION_NAME']))\n\n# Standard scaling\nscaler = StandardScaler()\ndose_scaled = scaler.fit_transform(data[['DOSE EQUIVALENT RATE (nSv/h)']])\n\n# Create a DataFrame from the scaled column\ndose_scaled_df = pd.DataFrame(dose_scaled, columns=['DOSE EQUIVALENT RATE (nSv/h)'])\npreprocessed_data = pd.concat([location_encoded_df, dose_scaled_df], axis=1)\npreprocessed_data.head()\n\n# Applying PCA\npca = PCA()\npca.fit(preprocessed_data)\n\n# Plotting the Cumulative Summation of the Explained Variance\nplt.figure(figsize=(8, 6))\nplt.plot(pca.explained_variance_ratio_.cumsum(), marker='o', linestyle='--')\nplt.title('Cumulative Explained Variance by PCA Components')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.grid(True)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Reduction_files/figure-html/cell-3-output-1.png){width=663 height=523}\n:::\n:::\n\n\n# Dimensionality Reduction with t-SNE\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# One-hot encode the \"LOCATION_NAME\" column\nencoder = OneHotEncoder(sparse=False)\nlocation_encoded = encoder.fit_transform(data[['LOCATION_NAME']])\n\n# Combine the one-hot encoded location data with the dose equivalent rate data\ncombined_data = pd.concat([pd.DataFrame(location_encoded), data['DOSE EQUIVALENT RATE (nSv/h)']], axis=1)\n\n# Device configuration - for Apple GPU\ndevice = torch.device('mps')\n\n# Convert the combined data to a PyTorch tensor\ndata_tensor = torch.tensor(combined_data.values, dtype=torch.float32).to(device)\n\n\n# Define a function to run t-SNE with different perplexity values and visualize the results\ndef run_tsne_and_visualize(data, perplexities, n_iter=1000):\n    for perplexity in perplexities:\n        # Apply t-SNE\n        tsne_results = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter, random_state=42).fit_transform(data)\n\n        # Plot the results\n        plt.figure(figsize=(8, 6))\n        sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1], alpha=0.5)\n        plt.title(f't-SNE with Perplexity = {perplexity}')\n        plt.xlabel('t-SNE Dimension 1')\n        plt.ylabel('t-SNE Dimension 2')\n        plt.show()\n\n# List of perplexity values to explore\nperplexities = [1, 5, 10]\n\n# Run and visualize t-SNE for each perplexity\nrun_tsne_and_visualize(data_tensor.cpu().numpy(), perplexities)\n```\n\n::: {.cell-output .cell-output-display}\n![](Reduction_files/figure-html/cell-4-output-1.png){width=679 height=523}\n:::\n\n::: {.cell-output .cell-output-display}\n![](Reduction_files/figure-html/cell-4-output-2.png){width=679 height=523}\n:::\n\n::: {.cell-output .cell-output-display}\n![](Reduction_files/figure-html/cell-4-output-3.png){width=679 height=523}\n:::\n:::\n\n\n# Reference\n\n[@usepa2021]\n\n",
    "supporting": [
      "Reduction_files"
    ],
    "filters": [],
    "includes": {}
  }
}